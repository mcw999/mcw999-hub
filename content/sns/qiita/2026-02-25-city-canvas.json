{
  "title": "Three.js + PostGIS + Meshy AIで位置情報ARプラットフォームを作った実装記録",
  "body": "## はじめに\n\n「街全体をキャンバスにできないか」という発想から始まったプロジェクト、**CityCanvas** の実装記録です。\n\nGPS座標にARコンテンツを紐づけ、他のユーザーがARカメラで発見・交流できるUGCプラットフォームです。技術スタックとしては Three.js / Mapbox GL JS / Supabase+PostGIS / Capacitor / Meshy AI を使いました。\n\n実装の過程でかなり試行錯誤があったので、失敗含めてそのまま書き残します。\n\n---\n\n## アーキテクチャの全体像\n\n```\n[ユーザーのブラウザ/ネイティブアプリ]\n  ├── Three.js (ARオーバーレイ・3Dレンダリング)\n  ├── Mapbox GL JS (地図UI)\n  └── Capacitor (iOS/Androidネイティブ化)\n\n[バックエンド]\n  └── Supabase\n       ├── PostgreSQL + PostGIS (空間データ管理)\n       └── Storage (3Dアセット・画像)\n\n[外部API]\n  └── Meshy AI (テキスト → 3Dモデル生成)\n```\n\nWebで動くPWAをベースに、Capacitorでネイティブラップするという構成です。カメラAPIや位置情報をネイティブで取りたかったので最終的にこの形に落ち着きました。\n\n---\n\n## 第1章: PostGISによる空間検索の実装\n\n### 最初のアプローチ（失敗）\n\n最初はシンプルに緯度経度をfloatカラムで持ち、アプリ側でフィルタリングしていました。\n\n```javascript\n// Before: アプリ側で全件取得して距離計算（最悪のアプローチ）\nconst { data: allContents } = await supabase\n  .from('ar_contents')\n  .select('*');\n\nconst nearbyContents = allContents.filter(content => {\n  const distance = calcHaversine(\n    userLat, userLng,\n    content.lat, content.lng\n  );\n  return distance < 500; // 500m以内\n});\n```\n\nコンテンツが数百件を超えたあたりから体感で重くなり始めました。当然ですが、全件取得は論外です。\n\n### PostGISに移行してSQL側に任せる\n\nSupabaseは PostGIS 拡張が有効化できるので、テーブル設計から変えました。\n\n```sql\n-- PostGIS拡張の有効化\nCREATE EXTENSION IF NOT EXISTS postgis;\n\n-- テーブル設計\nCREATE TABLE ar_contents (\n  id          UUID DEFAULT gen_random_uuid() PRIMARY KEY,\n  user_id     UUID REFERENCES auth.users(id),\n  title       TEXT NOT NULL,\n  content_type TEXT CHECK (content_type IN ('3d_object', 'text', 'photo')),\n  asset_url   TEXT,\n  payload     JSONB,  -- コンテンツ固有のメタデータ\n  location    GEOGRAPHY(Point, 4326) NOT NULL,  -- PostGIS地理型\n  created_at  TIMESTAMPTZ DEFAULT NOW()\n);\n\n-- 空間インデックス（これがないと意味がない）\nCREATE INDEX ar_contents_location_idx\n  ON ar_contents USING GIST (location);\n```\n\n`GEOGRAPHY` 型を使うことで、距離計算が球面上で正確に行われます。`GEOMETRY` でも動きますが、緯度経度をそのまま扱う場合は `GEOGRAPHY` の方が安全です。\n\nクライアント側のクエリはRPCで書きます：\n\n```sql\n-- Supabase上のPostgreSQL関数\nCREATE OR REPLACE FUNCTION get_nearby_contents(\n  user_lat  FLOAT,\n  user_lng  FLOAT,\n  radius_m  INT DEFAULT 500\n)\nRETURNS TABLE (\n  id           UUID,\n  title        TEXT,\n  content_type TEXT,\n  asset_url    TEXT,\n  payload      JSONB,\n  distance_m   FLOAT\n) LANGUAGE plpgsql AS $$\nBEGIN\n  RETURN QUERY\n  SELECT\n    c.id,\n    c.title,\n    c.content_type,\n    c.asset_url,\n    c.payload,\n    ST_Distance(\n      c.location,\n      ST_MakePoint(user_lng, user_lat)::GEOGRAPHY\n    ) AS distance_m\n  FROM ar_contents c\n  WHERE ST_DWithin(\n    c.location,\n    ST_MakePoint(user_lng, user_lat)::GEOGRAPHY,\n    radius_m\n  )\n  ORDER BY distance_m ASC;\nEND;\n$$;\n```\n\nクライアントからの呼び出しはシンプルになりました：\n\n```javascript\n// After: RPCで空間検索\nconst { data: nearbyContents, error } = await supabase\n  .rpc('get_nearby_contents', {\n    user_lat: currentPosition.latitude,\n    user_lng: currentPosition.longitude,\n    radius_m: 500\n  });\n\nif (error) throw error;\n// nearbyContentsには距離順にソートされたコンテンツが入ってくる\n```\n\n---\n\n## 第2章: Three.jsでARオーバーレイを作る\n\n### カメラ映像を背景にする\n\nブラウザのカメラAPIを使ってvideoタグに流し込み、その上にThree.jsのcanvasを重ねます。\n\n```javascript\n// ARビューの初期化\nasync function initARView() {\n  // カメラストリームの取得\n  const stream = await navigator.mediaDevices.getUserMedia({\n    video: {\n      facingMode: 'environment',  // 背面カメラ\n      width: { ideal: 1920 },\n      height: { ideal: 1080 }\n    }\n  });\n\n  const videoEl = document.getElementById('ar-video');\n  videoEl.srcObject = stream;\n  await videoEl.play();\n\n  // Three.jsシーンの初期化\n  const renderer = new THREE.WebGLRenderer({\n    canvas: document.getElementById('ar-canvas'),\n    alpha: true,          // 背景透過\n    antialias: true\n  });\n  renderer.setPixelRatio(window.devicePixelRatio);\n  renderer.setSize(window.innerWidth, window.innerHeight);\n  renderer.setClearColor(0x000000, 0);  // アルファ0で透過\n\n  const scene = new THREE.Scene();\n  const camera = new THREE.PerspectiveCamera(\n    70,\n    window.innerWidth / window.innerHeight,\n    0.01,\n    1000\n  );\n\n  return { renderer, scene, camera };\n}\n```\n\n### デバイス姿勢をカメラに反映する\n\n単純にコンテンツを固定座標に置くだけでは「AR」ではなく「3Dオーバーレイ」になってしまいます。デバイスの傾きをThree.jsカメラに反映させる必要があります。\n\n```javascript\n// DeviceOrientationEventを使ってカメラの向きを制御\nclass ARCameraController {\n  constructor(camera) {\n    this.camera = camera;\n    this.euler = new THREE.Euler();\n    this.quaternion = new THREE.Quaternion();\n    // モバイルブラウザの座標系補正用\n    this.screenOrientation = window.orientation || 0;\n  }\n\n  init() {\n    window.addEventListener('deviceorientation', (e) => {\n      this.updateCameraOrientation(e);\n    });\n    window.addEventListener('orientationchange', () => {\n      this.screenOrientation = window.orientation || 0;\n    });\n  }\n\n  updateCameraOrientation(event) {\n    const { alpha, beta, gamma } = event;\n    if (alpha === null) return;\n\n    // デバイス座標系 → Three.js座標系の変換\n    const alphaRad = THREE.MathUtils.degToRad(alpha);\n    const betaRad  = THREE.MathUtils.degToRad(beta);\n    const gammaRad = THREE.MathUtils.degToRad(gamma);\n    const orientRad = THREE.MathUtils.degToRad(this.screenOrientation);\n\n    this.euler.set(betaRad, alphaRad, -gammaRad, 'YXZ');\n    this.quaternion.setFromEuler(this.euler);\n\n    // 画面回転の補正\n    const correctionQuat = new THREE.Quaternion()\n      .setFromAxisAngle(new THREE.Vector3(0, 0, 1), -orientRad);\n    this.quaternion.multiply(correctionQuat);\n\n    this.camera.quaternion.copy(this.quaternion);\n  }\n}\n```\n\nここで座標系の変換ミスで最初2時間ほど溶かしました。`YXZ` のオイラー角順序指定と、画面回転補正が肝です。\n\n---\n\n## 第3章: Meshy AIでテキストから3Dモデルを生成する\n\nCityCanvasの目玉機能の一つが「テキストを入力するだけでその3Dオブジェクトを街に配置できる」というものです。\n\n```javascript\n// Meshy AI APIを使ったテキスト→3D生成\nasync function generateMeshFromText(prompt) {\n  // Step1: 生成ジョブの作成\n  const createRes = await fetch('https://api.meshy.ai/v2/text-to-3d', {\n    method: 'POST',\n    headers: {\n      'Authorization': `Bearer ${MESHY_API_KEY}`,\n      'Content-Type': 'application/json'\n    },\n    body: JSON.stringify({\n      mode: 'preview',     // previewで素早くプレビュー生成\n      prompt: prompt,\n      art_style: 'realistic',\n      negative_prompt: 'low quality, blurry'\n    })\n  });\n\n  const { result: jobId } = await createRes.json();\n\n  // Step2: ポーリングで完了を待つ\n  const modelUrl = await pollJobCompletion(jobId);\n  return modelUrl;\n}\n\nasync function pollJobCompletion(jobId, maxAttempts = 30) {\n  for (let i = 0; i < maxAttempts; i++) {\n    await new Promise(r => setTimeout(r, 3000)); // 3秒待機\n\n    const res = await fetch(`https://api.meshy.ai/v2/text-to-3d/${jobId}`, {\n      headers: { 'Authorization': `Bearer ${MESHY_API_KEY}` }\n    });\n    const job = await res.json();\n\n    if (job.status === 'SUCCEEDED') {\n      // GLBファイルのURLを返す\n      return job.model_urls.glb;\n    } else if (job.status === 'FAILED') {\n      throw new Error(`Mesh generation failed: ${job.task_error?.message}`);\n    }\n    // PENDING / IN_PROGRESS の場合はループ継続\n  }\n  throw new Error('Timeout: mesh generation took too long');\n}\n```\n\n生成されたGLBをThree.jsでロードして配置します：\n\n```javascript\nimport { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader.js';\n\nasync function loadAndPlaceModel(glbUrl, worldPosition) {\n  const loader = new GLTFLoader();\n  \n  return new Promise((resolve, reject) => {\n    loader.load(\n      glbUrl,\n      (gltf) => {\n        const model = gltf.scene;\n        \n        // ワールド座標に配置\n        model.position.copy(worldPosition);\n        model.scale.set(0.5, 0.5, 0.5); // サイズ調整\n        \n        // サイバーパンク風のエミッシブ効果を追加\n        model.traverse((node) => {\n          if (node.isMesh) {\n            node.material.emissive = new THREE.Color(0x00ffff);\n            node.material.emissiveIntensity = 0.3;\n          }\n        });\n        \n        scene.add(model);\n        resolve(model);\n      },\n      undefined,\n      reject\n    );\n  });\n}\n```\n\n---\n\n## 第4章: Capacitorでネイティブアプリ化\n\nPWAだけではカメラ/位置情報のパーミッション管理が不安定なシーンがあったため、Capacitorでネイティブラップしました。\n\n```javascript\n// capacitor.config.ts\nimport { CapacitorConfig } from '@capacitor/cli';\n\nconst config: CapacitorConfig = {\n  appId: 'com.citycanvas.app',\n  appName: 'CityCanvas',\n  webDir: 'dist',\n  plugins: {\n    Geolocation: {\n      // iOSのplist設定はこちらでは不要（native側で設定）\n    },\n    Camera: {\n      presentationStyle: 'fullscreen'\n    }\n  },\n  ios: {\n    contentInset: 'always'\n  }\n};\n\nexport default config;\n```\n\n位置情報の取得はCapacitorのGeolocationプラグインを使うことでブラウザAPIとの互換性を保てます：\n\n```javascript\nimport { Geolocation } from '@capacitor/geolocation';\n\nasync function startLocationTracking(onUpdate) {\n  // パーミッション確認\n  const permission = await Geolocation.checkPermissions();\n  if (permission.location !== 'granted') {\n    const req = await Geolocation.requestPermissions();\n    if (req.location !== 'granted') {\n      throw new Error('位置情報の権限が必要です');\n    }\n  }\n\n  // ウォッチで継続的に追跡\n  const watchId = await Geolocation.watchPosition(\n    {\n      enableHighAccuracy: true,\n      timeout: 10000,\n      maximumAge: 0\n    },\n    (position, err) => {\n      if (err) {\n        console.error('Location error:', err);\n        return;\n      }\n      onUpdate({\n        latitude: position.coords.latitude,\n        longitude: position.coords.longitude,\n        accuracy: position.coords.accuracy\n      });\n    }\n  );\n\n  return watchId; // clearWatch用にIDを返す\n}\n```\n\n---\n\n## つまずいたポイントまとめ\n\n| 問題 | 原因 | 解決策 |\n|------|------|--------|\n| DeviceOrientationがiOSで動かない | iOS 13以降でパーミッション要求が必要 | `DeviceOrientationEvent.requestPermission()` を呼ぶ |\n| PostGIS関数が型エラー | `GEOMETRY` と `GEOGRAPHY` の混在 | `ST_MakePoint(...) ::GEOGRAPHY` でキャスト統一 |\n| GLBロードがCORSエラー | Meshy AIのURL直アクセス | Supabase Storageに一度保存してから参",
  "tags": [
    "街をARで彩る",
    "位置情報ARプラットフォーム",
    "ユーザー生成3Dコンテンツ",
    "都市をキャンバスに",
    "ソーシャルAR体験"
  ]
}