{
  "title": "PostGISの空間クエリとThree.jsを組み合わせてARコンテンツを位置情報で管理する実装パターン",
  "body": "## はじめに\n\nソーシャルARプラットフォーム「CityCanvas」を開発する中で、技術的にもっとも面白いチャレンジのひとつが「位置情報ベースのARコンテンツ管理」でした。\n\nユーザーがGPS座標にARオブジェクトを配置し、近くにいる別のユーザーがそれをリアルタイムに発見する——という体験を実現するには、単純な緯度経度の一致チェックでは不十分です。**半径○メートル以内のコンテンツを高速に返す空間検索**が必要になります。\n\nこの記事では、Supabase（PostgreSQL + PostGIS）による空間クエリと、Three.jsによる3Dレンダリングを組み合わせた実装パターンを詳しく解説します。\n\n---\n\n## アーキテクチャ全体像\n\n```\n[ユーザーのGPS] → [Supabase PostGIS空間クエリ] → [ARコンテンツメタデータ取得]\n                                                          ↓\n[Mapbox GL JS] ← ─── [座標変換レイヤー] ─── → [Three.js 3Dレンダリング]\n```\n\n位置情報の流れとしては、\n\n1. ブラウザ/ネイティブアプリがGPS座標を取得\n2. PostGISで現在地周辺のARオブジェクトを空間検索\n3. 取得したメタデータ（座標・3Dモデルのパス等）をThree.jsシーンに反映\n4. カメラのデバイスオリエンテーションに合わせてオーバーレイ表示\n\nという構成になっています。\n\n---\n\n## PostGISによる空間検索の実装\n\n### テーブル設計\n\nまずSupabaseでARコンテンツを格納するテーブルを作成します。ポイントは`geography`型を使うことです。`geometry`型と違い、**地球の曲率を考慮したメートル単位の距離計算**が行えます。\n\n```sql\n-- PostGIS拡張を有効化\nCREATE EXTENSION IF NOT EXISTS postgis;\n\n-- ARコンテンツテーブル\nCREATE TABLE ar_contents (\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n  user_id UUID REFERENCES auth.users(id),\n  title TEXT NOT NULL,\n  content_type TEXT NOT NULL CHECK (content_type IN ('3d_model', 'text', 'photo')),\n  model_url TEXT,\n  thumbnail_url TEXT,\n  metadata JSONB DEFAULT '{}',\n  -- geography型でWGS84座標系（SRID=4326）を使用\n  location GEOGRAPHY(POINT, 4326) NOT NULL,\n  altitude FLOAT DEFAULT 0,\n  created_at TIMESTAMPTZ DEFAULT NOW(),\n  expires_at TIMESTAMPTZ\n);\n\n-- 空間インデックスを必ず作成する（検索パフォーマンスに直結）\nCREATE INDEX ar_contents_location_idx\n  ON ar_contents USING GIST(location);\n\n-- 有効期限切れを除外するインデックスも追加\nCREATE INDEX ar_contents_active_idx\n  ON ar_contents(expires_at)\n  WHERE expires_at IS NULL OR expires_at > NOW();\n```\n\n空間インデックス（GiSTインデックス）は**必須**です。インデックスなしでは全件スキャンになり、コンテンツが増えるほど指数的に遅くなります。\n\n### 現在地周辺のコンテンツを取得するRPC関数\n\n```sql\n-- 指定座標から指定半径内のARコンテンツを取得する関数\nCREATE OR REPLACE FUNCTION get_nearby_ar_contents(\n  user_lat FLOAT,\n  user_lng FLOAT,\n  radius_meters FLOAT DEFAULT 500,\n  content_limit INT DEFAULT 50\n)\nRETURNS TABLE (\n  id UUID,\n  user_id UUID,\n  title TEXT,\n  content_type TEXT,\n  model_url TEXT,\n  thumbnail_url TEXT,\n  metadata JSONB,\n  latitude FLOAT,\n  longitude FLOAT,\n  altitude FLOAT,\n  distance_meters FLOAT,\n  created_at TIMESTAMPTZ\n)\nLANGUAGE SQL\nSTABLE\nAS $$\n  SELECT\n    ac.id,\n    ac.user_id,\n    ac.title,\n    ac.content_type,\n    ac.model_url,\n    ac.thumbnail_url,\n    ac.metadata,\n    -- geography型からlatitude/longitudeを個別に取り出す\n    ST_Y(ac.location::geometry) AS latitude,\n    ST_X(ac.location::geometry) AS longitude,\n    ac.altitude,\n    -- ST_Distanceでメートル単位の距離を計算\n    ST_Distance(\n      ac.location,\n      ST_SetSRID(ST_MakePoint(user_lng, user_lat), 4326)::geography\n    ) AS distance_meters,\n    ac.created_at\n  FROM ar_contents ac\n  WHERE\n    -- ST_DWithinで半径内フィルタリング（インデックスが効く）\n    ST_DWithin(\n      ac.location,\n      ST_SetSRID(ST_MakePoint(user_lng, user_lat), 4326)::geography,\n      radius_meters\n    )\n    -- 有効期限チェック\n    AND (ac.expires_at IS NULL OR ac.expires_at > NOW())\n  ORDER BY distance_meters ASC\n  LIMIT content_limit;\n$$;\n```\n\n`ST_DWithin`が重要なポイントです。`ST_Distance(...) < radius`と書いても同じ結果になりますが、`ST_DWithin`はGiSTインデックスを活用できるため**圧倒的に高速**です。これはPostGISを使う上での基本的な作法です。\n\n---\n\n## フロントエンドからの呼び出し\n\nSupabase JSクライアントからRPC関数を呼ぶのは非常にシンプルです。\n\n```javascript\nimport { createClient } from '@supabase/supabase-js';\n\nconst supabase = createClient(\n  import.meta.env.VITE_SUPABASE_URL,\n  import.meta.env.VITE_SUPABASE_ANON_KEY\n);\n\n// ユーザーの現在地を取得してARコンテンツを検索する\nasync function fetchNearbyContents(radiusMeters = 500) {\n  return new Promise((resolve, reject) => {\n    navigator.geolocation.getCurrentPosition(\n      async (position) => {\n        const { latitude, longitude } = position.coords;\n\n        const { data, error } = await supabase.rpc('get_nearby_ar_contents', {\n          user_lat: latitude,\n          user_lng: longitude,\n          radius_meters: radiusMeters,\n          content_limit: 50,\n        });\n\n        if (error) {\n          reject(error);\n          return;\n        }\n\n        resolve({ contents: data, userPosition: { latitude, longitude } });\n      },\n      (err) => reject(err),\n      { enableHighAccuracy: true, timeout: 10000 }\n    );\n  });\n}\n\n// 使用例\nconst { contents, userPosition } = await fetchNearbyContents(300);\nconsole.log(`${contents.length}件のARコンテンツが見つかりました`);\n```\n\n---\n\n## Three.jsでARオブジェクトをワールド座標に配置する\n\n空間検索で取得したGPS座標を、Three.jsのワールド座標（メートル単位のXYZ）に変換する必要があります。ここが実装の肝です。\n\nGPSの緯度経度をThree.jsのXZ平面に投影するには、**Equirectangular近似**（基準点からの距離をメートル換算する方法）が実用的です。\n\n```javascript\nimport * as THREE from 'three';\nimport { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader.js';\n\nconst METERS_PER_DEGREE_LAT = 111320; // 緯度1度あたりのメートル数（定数）\n\nclass ARSceneManager {\n  constructor(canvas) {\n    this.scene = new THREE.Scene();\n    this.camera = new THREE.PerspectiveCamera(\n      75,\n      window.innerWidth / window.innerHeight,\n      0.1,\n      2000 // ARでは遠くのオブジェクトも見えるようにfarを大きく\n    );\n    this.renderer = new THREE.WebGLRenderer({\n      canvas,\n      alpha: true, // カメラ映像を背景にするので透明が必要\n      antialias: true,\n    });\n    this.renderer.setSize(window.innerWidth, window.innerHeight);\n    this.renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));\n\n    this.originPosition = null; // GPS座標の原点（ユーザーの現在地）\n    this.loader = new GLTFLoader();\n    this.arObjects = new Map(); // id → Three.js Object3D\n\n    this._setupLighting();\n    this._startRenderLoop();\n  }\n\n  // ユーザー現在地をシーンの原点として設定\n  setOrigin(latitude, longitude) {\n    this.originPosition = { latitude, longitude };\n  }\n\n  // GPS座標をThree.jsのXZ座標に変換\n  gpsToWorldPosition(latitude, longitude, altitude = 0) {\n    if (!this.originPosition) {\n      throw new Error('originPositionが設定されていません');\n    }\n\n    const deltaLat = latitude - this.originPosition.latitude;\n    const deltaLng = longitude - this.originPosition.longitude;\n\n    // 緯度方向（南北）はそのままメートル換算\n    const z = -deltaLat * METERS_PER_DEGREE_LAT; // Three.jsはZ軸が手前方向\n\n    // 経度方向（東西）は緯度によってスケールが変わる\n    const metersPerDegreeLng =\n      METERS_PER_DEGREE_LAT * Math.cos((latitude * Math.PI) / 180);\n    const x = deltaLng * metersPerDegreeLng;\n\n    // 高度はY軸（単位はメートル）\n    const y = altitude;\n\n    return new THREE.Vector3(x, y, z);\n  }\n\n  // ARコンテンツをシーンに追加\n  async addARContent(content) {\n    const worldPos = this.gpsToWorldPosition(\n      content.latitude,\n      content.longitude,\n      content.altitude\n    );\n\n    if (content.content_type === '3d_model' && content.model_url) {\n      await this._load3DModel(content, worldPos);\n    } else if (content.content_type === 'text') {\n      this._addTextLabel(content, worldPos);\n    }\n  }\n\n  async _load3DModel(content, worldPos) {\n    return new Promise((resolve, reject) => {\n      this.loader.load(\n        content.model_url,\n        (gltf) => {\n          const model = gltf.scene;\n          model.position.copy(worldPos);\n\n          // メタデータからスケールを取得（デフォルトは1.0）\n          const scale = content.metadata?.scale ?? 1.0;\n          model.scale.setScalar(scale);\n\n          // ユーザーデータとしてコンテンツIDを紐付け\n          model.userData = { contentId: content.id, ...content.metadata };\n\n          this.scene.add(model);\n          this.arObjects.set(content.id, model);\n          resolve(model);\n        },\n        undefined,\n        reject\n      );\n    });\n  }\n\n  _addTextLabel(content, worldPos) {\n    // テキストはSpriteMaterialでビルボード表示（常にカメラに向く）\n    const canvas = document.createElement('canvas');\n    canvas.width = 512;\n    canvas.height = 128;\n    const ctx = canvas.getContext('2d');\n\n    ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';\n    ctx.roundRect(0, 0, 512, 128, 16);\n    ctx.fill();\n\n    ctx.fillStyle = '#00ffcc'; // サイバーパンク風の色\n    ctx.font = 'bold 48px monospace';\n    ctx.textAlign = 'center';\n    ctx.fillText(content.title, 256, 80);\n\n    const texture = new THREE.CanvasTexture(canvas);\n    const material = new THREE.SpriteMaterial({ map: texture, transparent: true });\n    const sprite = new THREE.Sprite(material);\n\n    sprite.position.copy(worldPos);\n    sprite.position.y += 1.5; // 地面より少し上に表示\n    sprite.scale.set(4, 1, 1);\n\n    this.scene.add(sprite);\n    this.arObjects.set(content.id, sprite);\n  }\n\n  _setupLighting() {\n    const ambient = new THREE.AmbientLight(0xffffff, 0.6);\n    this.scene.add(ambient);\n\n    const directional = new THREE.DirectionalLight(0xffffff, 0.8);\n    directional.position.set(10, 20, 10);\n    this.scene.add(directional);\n  }\n\n  _startRenderLoop() {\n    const animate = () => {\n      requestAnimationFrame(animate);\n      this.renderer.render(this.scene, this.camera);\n    };\n    animate();\n  }\n}\n```\n\n### デバイスオリエンテーションとカメラ連動\n\nARとして機能させるために、デバイスの向きをThree.jsカメラに反映します。\n\n```javascript\nimport * as THREE from 'three';\nimport { DeviceOrientationControls } from './DeviceOrientationControls.js';\n\nclass ARCameraController {\n  constructor(camera) {\n    this.camera = camera;\n    this.controls = null;\n    this.videoStream = null;\n  }\n\n  async initialize() {\n    // カメラ映像をDOMに流す（Three.jsのcanvasの後ろに配置）\n    const video = document.getElementById('ar-video-background');\n    try {\n      this.videoStream = await navigator.mediaDevices.getUserMedia({\n        video: {\n          facingMode: 'environment', // 背面カメラを優先\n          width: { ideal: 1280 },\n          height: { ideal: 720 },\n        },\n      });\n      video.srcObject = this.videoStream;\n      await video.play();\n    } catch (err) {\n      console.warn('カメラアクセス失敗:', err);\n    }\n\n    // DeviceOrientationAPIでカメラの向きを追跡\n    if (typeof DeviceOrientationEvent !== 'undefined' &&\n        typeof DeviceOrientationEvent.requestPermission === 'function') {\n      // iOS 13+ではパーミッションが必要\n      const permission = await DeviceOrientationEvent.requestPermission();\n      if (permission !== '",
  "tags": [
    "街をARで彩る",
    "位置情報ARプラットフォーム",
    "ユーザー生成3Dコンテンツ",
    "都市をキャンバスに",
    "ソーシャルAR体験"
  ]
}