{
  "title": "TauriアプリでGitリポジトリをデータストアとして使うアーキテクチャ設計",
  "body": "## はじめに\n\n個人開発のPR自動化ツール「PRダッシュボード」を開発する中で、興味深い設計パターンにたどり着いた。**GitHubリポジトリをアプリケーションのデータストアとして活用する**というアプローチだ。\n\n通常のデスクトップアプリならSQLiteやローカルJSONファイルを使うところを、あえてGitリポジトリに乗せることで「デスクトップアプリとGitHub Actionsワークフローがデータを共有する」という構成が自然に実現できた。この記事では、Tauri v2でこのアーキテクチャを実装した際の具体的なコードと、開発中に遭遇した落とし穴を紹介する。\n\n---\n\n## Gitリポジトリをデータストアにする設計の概要\n\nPRダッシュボードでは `mcw999-hub` というGitHubリポジトリを中央データストアとして使っている。構造はこうだ。\n\n```\nmcw999-hub/\n├── content/\n│   ├── projects/\n│   │   ├── my-app.json        # プロジェクト定義\n│   │   └── another-tool.json\n│   └── meta/\n│       ├── post-history.json  # 投稿履歴\n│       └── traffic-history.json  # GitHubトラフィック累積データ\n└── .github/\n    └── workflows/\n        └── post-content.yml   # 投稿ワークフロー\n```\n\n**なぜこの設計を選んだか？**\n\n- デスクトップアプリが書いたデータをGitHub Actionsが読める（逆も然り）\n- すべての変更がGitコミットとして残るため、差分追跡が無料でできる\n- GitHub APIを使えばどのマシンからでもデータにアクセスできる\n- GitHub Actionsのシークレット管理でAPIトークンを安全に保管できる\n\nこのアーキテクチャの核となるRust側のデータ同期処理を見ていこう。\n\n---\n\n## Rust側のGitデータ同期実装\n\nTauri v2ではバックエンド処理をRustで書き、`#[tauri::command]`アトリビュートでフロントエンドから呼び出す。\n\nデータ取得の際、リモートから最新データを pull しつつ、ローカルの編集中データを守る処理が肝になる。最初は単純に `git pull` を実行していたが、**ローカルの作業中変更が吹き飛ぶバグ**を踏んだ。`git stash → git pull --ff-only → git stash pop` の順序が重要で、当初 `stash drop` にしていたため変更が消失していた。\n\n```rust\n#[tauri::command]\npub async fn refresh_analytics(data_store_path: String) -> Result<(), String> {\n    let repo_path = PathBuf::from(&data_store_path);\n\n    // ローカルの未コミット変更を退避\n    let stash_result = Command::new(\"git\")\n        .args([\"stash\", \"push\", \"-m\", \"pr-dashboard-auto-stash\"])\n        .current_dir(&repo_path)\n        .output()\n        .map_err(|e| e.to_string())?;\n\n    let stashed = String::from_utf8_lossy(&stash_result.stdout)\n        .contains(\"Saved working directory\");\n\n    // fast-forward のみ許可（マージコミットを作らない）\n    let pull_result = Command::new(\"git\")\n        .args([\"pull\", \"--ff-only\"])\n        .current_dir(&repo_path)\n        .output()\n        .map_err(|e| e.to_string())?;\n\n    if !pull_result.status.success() {\n        // pull 失敗時も stash を復元してから返す\n        if stashed {\n            let _ = Command::new(\"git\")\n                .args([\"stash\", \"pop\"])\n                .current_dir(&repo_path)\n                .output();\n        }\n        return Err(format!(\n            \"git pull failed: {}\",\n            String::from_utf8_lossy(&pull_result.stderr)\n        ));\n    }\n\n    // stash を復元（drop ではなく pop で安全に戻す）\n    if stashed {\n        Command::new(\"git\")\n            .args([\"stash\", \"pop\"])\n            .current_dir(&repo_path)\n            .output()\n            .map_err(|e| e.to_string())?;\n    }\n\n    Ok(())\n}\n```\n\n`--ff-only` を指定しているのは、デスクトップアプリとGitHub Actionsが同時にプッシュした際に意図しないマージコミットが生成されるのを防ぐためだ。コンフリクトが起きた場合は明示的にエラーとして返し、ユーザーに手動解決を促す。\n\n---\n\n## GitHub Traffic APIの14日制限を回避するデータ蓄積設計\n\nGitHub Traffic APIには**直近14日分のデータしか返さない**という制限がある。長期的なトラフィック推移を見たい場合、これは致命的だ。\n\n解決策として、取得したデータを `traffic-history.json` にマージしながら蓄積する仕組みを実装した。\n\n```rust\n#[derive(Serialize, Deserialize, Clone)]\nstruct TrafficEntry {\n    timestamp: String,\n    views: u64,\n    unique_visitors: u64,\n    clones: u64,\n}\n\n#[tauri::command]\npub async fn fetch_and_merge_traffic(\n    repo: String,\n    token: String,\n    history_path: String,\n) -> Result<Vec<TrafficEntry>, String> {\n    // GitHub API から直近14日分を取得\n    let client = reqwest::Client::new();\n    let views_resp = client\n        .get(format!(\"https://api.github.com/repos/{}/traffic/views\", repo))\n        .header(\"Authorization\", format!(\"Bearer {}\", token))\n        .header(\"User-Agent\", \"pr-dashboard\")\n        .send()\n        .await\n        .map_err(|e| e.to_string())?\n        .json::<serde_json::Value>()\n        .await\n        .map_err(|e| e.to_string())?;\n\n    // 既存の履歴ファイルを読み込む\n    let history_file = PathBuf::from(&history_path);\n    let mut existing: Vec<TrafficEntry> = if history_file.exists() {\n        let content = fs::read_to_string(&history_file).map_err(|e| e.to_string())?;\n        serde_json::from_str(&content).unwrap_or_default()\n    } else {\n        Vec::new()\n    };\n\n    // API レスポンスを TrafficEntry に変換\n    let new_entries: Vec<TrafficEntry> = views_resp[\"views\"]\n        .as_array()\n        .unwrap_or(&vec![])\n        .iter()\n        .filter_map(|v| {\n            Some(TrafficEntry {\n                timestamp: v[\"timestamp\"].as_str()?.to_string(),\n                views: v[\"count\"].as_u64()?,\n                unique_visitors: v[\"uniques\"].as_u64()?,\n                clones: 0, // clones は別エンドポイントで取得\n            })\n        })\n        .collect();\n\n    // タイムスタンプをキーとして重複排除しながらマージ\n    for new_entry in new_entries {\n        if let Some(existing_entry) = existing\n            .iter_mut()\n            .find(|e| e.timestamp == new_entry.timestamp)\n        {\n            // 既存エントリを上書き（より新しいデータで更新）\n            *existing_entry = new_entry;\n        } else {\n            existing.push(new_entry);\n        }\n    }\n\n    // タイムスタンプでソート\n    existing.sort_by(|a, b| a.timestamp.cmp(&b.timestamp));\n\n    // ファイルに書き戻す\n    let json = serde_json::to_string_pretty(&existing).map_err(|e| e.to_string())?;\n    fs::write(&history_file, json).map_err(|e| e.to_string())?;\n\n    Ok(existing)\n}\n```\n\nこのマージ処理のポイントは**タイムスタンプをキーとした upsert**だ。APIは同じ日のデータを複数回取得すると最新値を返すので、既存エントリを上書きする形にしている。これにより、14日より前のデータが失われることなく蓄積され続ける。\n\n---\n\n## Tauri v2の型安全なIPCとuseApiフック設計\n\nTauri v2では `invoke<T>()` のジェネリクスでRustコマンドの戻り値型を指定できる。これを活用して、フロントエンド側に型安全なAPIレイヤーを構築した。\n\nすべてのIPCコールを `useApi` フックに集約するのが設計のポイントだ。コンポーネントから直接 `invoke` を呼ぶと、型定義やエラーハンドリングが散らばってメンテナンスコストが跳ね上がる。\n\n```typescript\n// types/api.ts\nexport interface ProjectMeta {\n  slug: string;\n  name: string;\n  nameJa?: string;\n  tagline: string;\n  description: string;\n  techStack: string[];\n  category: ProjectCategory;\n  targetAudience: string[];\n  autoPromote: boolean;\n}\n\nexport type ProjectCategory =\n  | \"crypto\" | \"saas\" | \"tool\" | \"platform\" | \"finance\"\n  | \"game\" | \"education\" | \"health\" | \"social\" | \"mobile-app\" | \"other\";\n\nexport interface TrafficEntry {\n  timestamp: string;\n  views: number;\n  uniqueVisitors: number;\n  clones: number;\n}\n\n// hooks/useApi.ts\nimport { invoke } from \"@tauri-apps/api/core\";\nimport { useMemo } from \"react\";\n\nfunction createApi() {\n  return {\n    // プロジェクト一覧取得\n    listProjects: () =>\n      invoke<ProjectMeta[]>(\"list_projects\"),\n\n    // プロジェクト保存（楽観的UI更新を想定した設計）\n    saveProject: (project: ProjectMeta) =>\n      invoke<void>(\"save_project\", { project }),\n\n    // トラフィック履歴の取得・マージ\n    fetchAndMergeTraffic: (repo: string, token: string, historyPath: string) =>\n      invoke<TrafficEntry[]>(\"fetch_and_merge_traffic\", {\n        repo,\n        token,\n        historyPath,\n      }),\n\n    // データストアの同期\n    refreshAnalytics: (dataStorePath: string) =>\n      invoke<void>(\"refresh_analytics\", { dataStorePath }),\n\n    // プロジェクトスキャン（Claude -p モード）\n    scanProjectWithClaude: (projectPath: string) =>\n      invoke<ProjectMeta>(\"scan_project_with_claude\", { projectPath }),\n  };\n}\n\nexport function useApi() {\n  // useMemo でメモ化しないと毎レンダーで新しいオブジェクトが生成され、\n  // 子コンポーネントへの props として渡した際に不要な再レンダーが発生する\n  return useMemo(() => createApi(), []);\n}\n```\n\n`useMemo(() => createApi(), [])` のメモ化は見落としやすいが重要だ。`createApi()` が返すオブジェクトは毎回同じ関数参照を持つが、**オブジェクト自体は新しいインスタンス**なので、`useEffect` の依存配列や `React.memo` でラップした子コンポーネントへの props として渡すと意図しない再レンダーを引き起こす。\n\n楽観的UI更新も `useApi` と組み合わせることでシンプルに書ける。\n\n```typescript\n// components/ProjectCard.tsx（楽観的UI更新の例）\nfunction ProjectCard({ project }: { project: ProjectMeta }) {\n  const api = useApi();\n  const [autoPromote, setAutoPromote] = useState(project.autoPromote);\n\n  const handleToggleAutoPromote = async () => {\n    // 即座にUIを更新（楽観的更新）\n    const optimisticValue = !autoPromote;\n    setAutoPromote(optimisticValue);\n\n    try {\n      await api.saveProject({ ...project, autoPromote: optimisticValue });\n    } catch (error) {\n      // 失敗時はロールバック + エラー表示\n      // ここでロールバックしないと UI とサーバー状態が乖離するサイレントバグになる\n      setAutoPromote(project.autoPromote);\n      console.error(\"Failed to toggle autoPromote:\", error);\n      toast.error(\"設定の保存に失敗しました。元の状態に戻しました。\");\n    }\n  };\n\n  return (\n    <div className=\"project-card\">\n      <h3>{project.nameJa ?? project.name}</h3>\n      <button onClick={handleToggleAutoPromote}>\n        {autoPromote ? \"自動投稿: ON\" : \"自動投稿: OFF\"}\n      </button>\n    </div>\n  );\n}\n```\n\n楽観的UI更新でロールバック処理を省くと、APIが失敗してもUIは成功した状態のまま残る**サイレントバグ**になる。必ずロールバックとエラー表示をセットで実装する。\n\n---\n\n## Claude CLIの非対話実行と--printモードへの移行\n\nプロジェクトスキャナーの実装で最も試行錯誤したのが**Claude CLIの自動実行**だ。\n\n最初は `SendKeys + PowerShell の AppActivate` でCLIのターミナルウィンドウを自動操作していた。フォルダ信頼承認→プロンプト貼り付け→Enter送信を `Sleep` で制御する方式だったが、マシン負荷やCLI起動速度によってタイミングがずれ、「分析中」のまま永遠に止まる問題が頻発した。\n\n`claude --print` モード（`-p`）への全面切り替えで完全解決した。\n\n```rust\n#[tauri::command]\npub async fn scan_project_with_claude(project_path: String) -> Result<ProjectMeta, String> {\n    let path = PathBuf::from(&project_path);\n\n    // Windows で日本語パスが含まれる場合の回避策\n    // PowerShell の Scripting.FileSystemObject で 8.3 ",
  "tags": [
    "個人開発",
    "PR自動化",
    "コンテンツ生成",
    "Claude AI",
    "Tauri"
  ]
}